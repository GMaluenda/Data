{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Noms de tots els fitxers que s'han d'utilitzar\"\"\"\n",
    "\n",
    "df_names = ['Aura_with_level1', 'Guillem_with_level1', 'Guillem_with_level2', 'Guillem_without_level2', 'Pau_with_level1', 'Fiona_with_level1', 'Oscar_with_level1', 'Salva_with_level1', 'Salva_with_level3','Pau_without_level2', 'Fiona_without_level2', 'Oscar_without_level2', 'Salva_without_level2' ]\n",
    "df_names_csv = [i+'.csv' for i in df_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcions per treure les dades que ens dona l'eyetracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(fitxer):\n",
    "\n",
    "    \"\"\"Aquesta funció agafa el gazedata i ens retorna la informació d'aquest en format .csv, en aquest cas només retornem timestamp, gaze2d i els diàmetres de les pupiles\"\"\"\n",
    "\n",
    "    file = gzip.open('Data/raw/'+ fitxer + '/gazedata.gz','rb')\n",
    "    file_content = file.read().decode(\"utf-8\")\n",
    "    file.close()\n",
    "    data = []\n",
    "    left_open = []\n",
    "    right_open = []\n",
    "    contents = file_content.split(\"\\n\")\n",
    "\n",
    "    for content in contents[:-1]:\n",
    "        json_content = json.loads(content)\n",
    "        if json_content['data'] != {}:\n",
    "            if json_content['data']['eyeleft'] == {}:\n",
    "                dades = {\n",
    "                    'timestamp': json_content['timestamp'],\n",
    "                    'gaze2d_x': json_content['data']['gaze2d'][0],\n",
    "                    'gaze2d_y': json_content['data']['gaze2d'][1],\n",
    "                    'eyeleft_pupildiameter': 0,\n",
    "                    'eyeright_pupildiameter': json_content['data']['eyeright']['pupildiameter']\n",
    "                }\n",
    "\n",
    "            elif json_content['data']['eyeright'] == {}:\n",
    "                dades = {\n",
    "                    'timestamp': json_content['timestamp'],\n",
    "                    'gaze2d_x': json_content['data']['gaze2d'][0],\n",
    "                    'gaze2d_y': json_content['data']['gaze2d'][1],\n",
    "                    'eyeleft_pupildiameter': json_content['data']['eyeleft']['pupildiameter'],\n",
    "                    'eyeright_pupildiameter': 0\n",
    "                }\n",
    "\n",
    "            else:\n",
    "                dades = {\n",
    "                    'timestamp': json_content['timestamp'],\n",
    "                    'gaze2d_x': json_content['data']['gaze2d'][0],\n",
    "                    'gaze2d_y': json_content['data']['gaze2d'][1],\n",
    "                    'eyeleft_pupildiameter': json_content['data']['eyeleft']['pupildiameter'],\n",
    "                    'eyeright_pupildiameter': json_content['data']['eyeright']['pupildiameter']\n",
    "                }\n",
    "            \n",
    "        else:\n",
    "            dades = {\n",
    "                'timestamp': json_content['timestamp'],\n",
    "                'gaze2d_x': 0,\n",
    "                'gaze2d_y': 0,\n",
    "                'eyeleft_pupildiameter': 0,\n",
    "                'eyeright_pupildiameter': 0\n",
    "                }\n",
    "\n",
    "        data.append(dades)\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    data.to_csv('Data/gazedata_csv/'+'gazedata_'+fitxer+'.csv', index=False)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_names:\n",
    "    get_data(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcions pels csv que ens torna el Heat the Chair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_csv_heatthechair (fitxer):\n",
    "\n",
    "    \"\"\"Amb aquesta funció canviem el format de les dates i també fem que les interrupcions en que el seu begin_time és now (en el csv és 0) ens aparegui com a begin time el moment en que arriba la notificació\"\"\"\n",
    "\n",
    "    df = pd.read_csv('Data/csv_heatthechair/'+fitxer)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    df['interruption_begin_time'] = pd.to_datetime(df['interruption_begin_time'], unit='s')\n",
    "    df['interruption_due_time'] = pd.to_datetime(df['interruption_due_time'], unit='s')\n",
    "\n",
    "    # Com originalment el format de la data està en unix, el 0 en datetime és el 1970-01-01 00:00:00\n",
    "    zero_time = pd.to_datetime('1970-01-01 00:00:00')\n",
    "    df['interruption_begin_time'] = df['interruption_begin_time'].apply(lambda x: 0 if x == zero_time else x)\n",
    "    df['interruption_due_time'] = df['interruption_due_time'].apply(lambda x: 0 if x == zero_time else x)\n",
    "\n",
    "    # En aquestes dues llistes guardem els moments en que comencen i acaben les interrupcion que comencen 'now'\n",
    "    list_interruption_begin_time = []\n",
    "    list_interruption_due_time = []\n",
    "\n",
    "    # Per poder canviar elements concrets del df busco els indexs de les columnes on es voldran fer el canvis\n",
    "    columns = df.columns.to_list()\n",
    "    loc_interruption_begin_time = columns.index('interruption_begin_time')\n",
    "    loc_interruption_due_time = columns.index('interruption_due_time')\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if (df.iloc[i]['interruption_begin_time'] == 0) & (df.iloc[i]['interruption_due_time'] != 0):\n",
    "\n",
    "            # Si la interruption due time no està en list_interruption_due_time vol dir que comença ara la interrupció\n",
    "            if df.iloc[i]['interruption_due_time'] not in list_interruption_due_time:\n",
    "                df.iloc[i,loc_interruption_begin_time] = df.iloc[i]['timestamp']\n",
    "                # Guardem el interruption_due_time per saber que ja ha començat aquesta interrupció \n",
    "                list_interruption_due_time.append(df.iloc[i]['interruption_due_time'])\n",
    "                list_interruption_begin_time.append(df.iloc[i]['interruption_begin_time'])\n",
    "            else:\n",
    "                # Si la interrucpió acaba entrarà en aquest else i el interruption_begin_time el posem el temps en què va començar la interrupció, per això s'utilitza la list_interruption_begin_time\n",
    "                df.iloc[i,loc_interruption_begin_time] = list_interruption_begin_time[list_interruption_due_time.index(df.iloc[i]['interruption_due_time'])]\n",
    "\n",
    "    df.to_csv('Data/csv_interruptions/'+fitxer, index=False)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7436/2200089234.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2023-10-10 15:07:27' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[i,loc_interruption_begin_time] = df.iloc[i]['timestamp']\n"
     ]
    }
   ],
   "source": [
    "for i in df_names_csv:\n",
    "    fix_csv_heatthechair(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COORDINAR ELS TIMESTAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El timestamp que ens retornen les ulleres són el temps que ha trascorregut des de que s'ha iniciat la gravació. En l'arxiu recording.g3 tenirm el moment d'inici (creation) i utilitzant-lo podem posar la data exacta de cada mesura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinar_timestamp(gazedata, interruptions, fitxer):\n",
    "    file = open('Data/raw/'+fitxer+'/recording.g3','r')       \n",
    "    file_content = file.read()\n",
    "    file.close()\n",
    "    file_content = json.loads(file_content)\n",
    "    start_recording = pd.Timestamp(file_content['created'])\n",
    "    start_recording = start_recording.tz_convert(tz=file_content['timezone'])\n",
    "    new_timestamp = start_recording + pd.to_timedelta(gazedata['timestamp'], unit='s') \n",
    "\n",
    "    new_timestamp = new_timestamp.dt.tz_localize(None)\n",
    "    \n",
    "    return new_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>gaze2d_x</th>\n",
       "      <th>gaze2d_y</th>\n",
       "      <th>eyeleft_pupildiameter</th>\n",
       "      <th>eyeright_pupildiameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-10 16:30:52.263946</td>\n",
       "      <td>0.5885</td>\n",
       "      <td>0.8835</td>\n",
       "      <td>3.173</td>\n",
       "      <td>2.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-10 16:30:52.283932</td>\n",
       "      <td>0.5886</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>3.177</td>\n",
       "      <td>2.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-10 16:30:52.304018</td>\n",
       "      <td>0.5887</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>3.185</td>\n",
       "      <td>2.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-10 16:30:52.324004</td>\n",
       "      <td>0.5888</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>3.188</td>\n",
       "      <td>2.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-10 16:30:52.344091</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>3.199</td>\n",
       "      <td>2.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33801</th>\n",
       "      <td>2023-10-10 16:42:09.649491</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.6739</td>\n",
       "      <td>4.144</td>\n",
       "      <td>3.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33802</th>\n",
       "      <td>2023-10-10 16:42:09.669479</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.6729</td>\n",
       "      <td>4.144</td>\n",
       "      <td>3.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33803</th>\n",
       "      <td>2023-10-10 16:42:09.689563</td>\n",
       "      <td>0.4602</td>\n",
       "      <td>0.6714</td>\n",
       "      <td>4.157</td>\n",
       "      <td>3.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33804</th>\n",
       "      <td>2023-10-10 16:42:09.709551</td>\n",
       "      <td>0.4628</td>\n",
       "      <td>0.6645</td>\n",
       "      <td>4.152</td>\n",
       "      <td>3.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33805</th>\n",
       "      <td>2023-10-10 16:42:09.729635</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>0.5763</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33806 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       timestamp  gaze2d_x  gaze2d_y  eyeleft_pupildiameter  \\\n",
       "0     2023-10-10 16:30:52.263946    0.5885    0.8835                  3.173   \n",
       "1     2023-10-10 16:30:52.283932    0.5886    0.8800                  3.177   \n",
       "2     2023-10-10 16:30:52.304018    0.5887    0.8785                  3.185   \n",
       "3     2023-10-10 16:30:52.324004    0.5888    0.8769                  3.188   \n",
       "4     2023-10-10 16:30:52.344091    0.5890    0.8753                  3.199   \n",
       "...                          ...       ...       ...                    ...   \n",
       "33801 2023-10-10 16:42:09.649491    0.4604    0.6739                  4.144   \n",
       "33802 2023-10-10 16:42:09.669479    0.4604    0.6729                  4.144   \n",
       "33803 2023-10-10 16:42:09.689563    0.4602    0.6714                  4.157   \n",
       "33804 2023-10-10 16:42:09.709551    0.4628    0.6645                  4.152   \n",
       "33805 2023-10-10 16:42:09.729635    0.5365    0.5763                  0.000   \n",
       "\n",
       "       eyeright_pupildiameter  \n",
       "0                       2.834  \n",
       "1                       2.837  \n",
       "2                       2.842  \n",
       "3                       2.845  \n",
       "4                       2.849  \n",
       "...                       ...  \n",
       "33801                   3.499  \n",
       "33802                   3.502  \n",
       "33803                   3.499  \n",
       "33804                   3.372  \n",
       "33805                   3.020  \n",
       "\n",
       "[33806 rows x 5 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En el cas de gazedata_Aura_with_level1\n",
    "interruptions = pd.read_csv('Data/csv_interruptions/Aura_with_level1.csv')\n",
    "gazedata = pd.read_csv('Data/gazedata_csv/gazedata_Aura_with_level1')\n",
    "\n",
    "gazedata['timestamp'] = coordinar_timestamp(gazedata, interruptions, '20231010T143052Z')\n",
    "gazedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trobar_workload(interruptions):\n",
    "\n",
    "    \"\"\"Amb aquesta funció trobarem quin workload hi ha en cada instant que dura el joc\"\"\"\n",
    "\n",
    "    interruption_in = interruptions[interruptions['interruption_in'] != 0]\n",
    "    interruption_out = interruptions[interruptions['interruption_out'] != 0]\n",
    "    interruption_in = interruption_in.sort_values(by=['interruption_in'] )\n",
    "    interruption_out = interruption_out.sort_values(by=['interruption_out'] )\n",
    "    time_interruption_in = list(pd.to_datetime(interruption_in['timestamp']).dt.strftime(\"%H:%M:%S\"))\n",
    "    time_interruption_out = list(pd.to_datetime(interruption_out['timestamp']).dt.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    end_time = interruptions['timestamp'].iloc[-1][-8:]\n",
    "\n",
    "    # Quan s'acabi la partida hi ha haurà interrupcions que encara seguiran però no s'hauran resolt, això fa qut time_interrution_in i time_interruption_out tinguin llargades diferents\n",
    "    # per això per cada interrupció que no ha acabat posarem que el temps en que acaba és quan acaba el joc (end_time)\n",
    "    diferencia = len(time_interruption_in) - len(time_interruption_out)\n",
    "    for i in range(0,diferencia):\n",
    "        time_interruption_out.append(end_time)\n",
    "\n",
    "    # Per poder comparar temps passo el temps de time_interruption_ a timedelta\n",
    "    time_interruption_in_timedelta = list()\n",
    "    time_interruption_out_timedelta = list()\n",
    "    for i in time_interruption_in:\n",
    "        time_interruption_in_timedelta.append(pd.to_timedelta(i))\n",
    "    for i in time_interruption_out:\n",
    "        time_interruption_out_timedelta.append(pd.to_timedelta(i))\n",
    "\n",
    "    # Creem una seqüència amb tots els segons que dura el joc\n",
    "    # timedelta_range no accepta com arguments Timestamp, per això interruptions['timestamp'] no l'he passata datatime i es llegeix com a string \n",
    "    game_duration = pd.timedelta_range(interruptions['timestamp'][0][-8:], interruptions['timestamp'][len(interruptions)-1][-8:], freq='s')\n",
    "\n",
    "    # Ara el que farem és anar un per un per cada segon que ha durat el joc i veure si es trobava dins d'una o més interrupcions \n",
    "    workload = {}\n",
    "    for i in game_duration:\n",
    "        counter = 0\n",
    "        for j in range(0,len(time_interruption_in)):\n",
    "            if(time_interruption_in_timedelta[j] <= i <= time_interruption_out_timedelta[j]):\n",
    "                counter += 1\n",
    "\n",
    "        workload[str(i)[-8:]] = counter\n",
    "\n",
    "    return workload\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workload alternatiu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_workload_2(row, interruptions):\n",
    "\n",
    "    workload = 0\n",
    "\n",
    "    # Check if \"piece\" column has a value of -1, and if so, add 2 to the workload\n",
    "    if row['piece'] == -1:\n",
    "        workload += 2\n",
    "\n",
    "    # Calculem el temps transcorregut\n",
    "    # interruptions['timestamp'] = pd.to_datetime(interruptions['timestamp'])\n",
    "    total_time = (interruptions['timestamp'].max() - interruptions['timestamp'].min()).total_seconds()\n",
    "\n",
    "    # Calculate the proportion of time elapsed\n",
    "    timestamp = row['timestamp']\n",
    "    elapsed_time = (timestamp - interruptions['timestamp'].min()).total_seconds()\n",
    "    time_proportion = elapsed_time / total_time\n",
    "\n",
    "    # Add the time proportion to the workload\n",
    "    workload += time_proportion\n",
    "\n",
    "    return workload\n",
    "\n",
    "\n",
    "def trobar_workload_2(interruptions):\n",
    "\n",
    "    # Primer fem les operacions que necessiten que el timestamp estigui com a string\n",
    "    timestamp_hms = list(pd.to_datetime(interruptions['timestamp']).dt.strftime(\"%H:%M:%S\"))\n",
    "    timestamp_timedelta = [ pd.to_timedelta(x) for x in timestamp_hms]\n",
    "    # Creem un timdelta_range per poder mirar cada segon que dura el joc\n",
    "    game_duration = pd.timedelta_range(interruptions['timestamp'][0][-8:], interruptions['timestamp'][len(interruptions)-1][-8:], freq='s')\n",
    "\n",
    "    # Ara passem el timestamp a datetime\n",
    "    interruptions['timestamp'] = pd.to_datetime(interruptions['timestamp'])\n",
    "\n",
    "    # Calculem el workload_2 utilitzant la funció calculate_workload_2\n",
    "    interruptions['workload_2'] = interruptions.apply(lambda row: calculate_workload_2(row, interruptions), axis=1) \n",
    "\n",
    "    # Ara el que farem és anar un per un per cada segon que ha durat el joc i veure si es trobava dins d'una o més interrupcions \n",
    "    workload_2 = {}\n",
    "    index = 1\n",
    "    for i in game_duration:\n",
    "\n",
    "        if i < timestamp_timedelta[index]:\n",
    "            workload_2[str(i)[-8:]] = interruptions.iloc[index-1]['workload_2']\n",
    "        elif i >= timestamp_timedelta[index]:\n",
    "            workload_2[str(i)[-8:]] = interruptions.iloc[index]['workload_2']\n",
    "            index += 1\n",
    "\n",
    "    return workload_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "interruptions = pd.read_csv('Data/csv_interruptions/Aura_with_level1.csv')\n",
    "\n",
    "# Primer fem les operacions que necessiten que el timestamp estigui com a string\n",
    "timestamp_hms = list(pd.to_datetime(interruptions['timestamp']).dt.strftime(\"%H:%M:%S\"))\n",
    "timestamp_timedelta = [ pd.to_timedelta(x) for x in timestamp_hms]\n",
    "game_duration = pd.timedelta_range(interruptions['timestamp'][0][-8:], interruptions['timestamp'][len(interruptions)-1][-8:], freq='s')\n",
    "\n",
    "# Ara passem el timestamp a datetime\n",
    "interruptions['timestamp'] = pd.to_datetime(interruptions['timestamp'])\n",
    "\n",
    "# Calculem el workload_2 utilitzant la funció calculate_workload_2\n",
    "interruptions['workload_2'] = interruptions.apply(lambda row: calculate_workload_2(row, interruptions), axis=1) \n",
    "\n",
    "# Ara el que farem és anar un per un per cada segon que ha durat el joc i veure si es trobava dins d'una o més interrupcions \n",
    "workload_2 = {}\n",
    "index = 1\n",
    "for i in game_duration:\n",
    "\n",
    "    if i < timestamp_timedelta[index]:\n",
    "        workload_2[str(i)[-8:]] = interruptions.iloc[index-1]['workload_2']\n",
    "    elif i >= timestamp_timedelta[index]:\n",
    "        workload_2[str(i)[-8:]] = interruptions.iloc[index]['workload_2']\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generem el data frame de gazedata amb els dos workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gazedata_definitiu(fitxer):\n",
    "\n",
    "    \"\"\"Amb aquesta fucnió retornem el gazedata amb el workload corresponent a cada fila\"\"\"\n",
    "\n",
    "    interruptions = pd.read_csv('Data/csv_interruptions/'+fitxer+'.csv')\n",
    "    gazedata = pd.read_csv('Data/gazedata_csv/gazedata_'+fitxer+'.csv')\n",
    "\n",
    "    gazedata['timestamp'] = coordinar_timestamp(gazedata, interruptions, fitxer)\n",
    "\n",
    "    # Ara escurcem el gazedata al temps en que es juga al joc\n",
    "    gazedata = gazedata[(pd.to_datetime(interruptions['timestamp'][0]) <= gazedata['timestamp']) &  (gazedata['timestamp'] <= interruptions['timestamp'][len(interruptions)-1])]\n",
    "\n",
    "    # Resetejem l'índex per despŕes no tenir problemes\n",
    "    gazedata.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \"\"\"Primer posem el workload que ens diu el nombre d'interrupcions simultànies\"\"\"\n",
    "\n",
    "    workload = trobar_workload(interruptions)\n",
    "\n",
    "    def assignar_workload(x):\n",
    "\n",
    "        \"\"\"Amb aquesta funció trobem per cada instant que hi ha de gazedata quin workload li correspon, workload és un diccionari que s'ha trobat prèviament\"\"\"\n",
    "\n",
    "        #trobem l'espai que separa la data amb l'hora perque no ens interessa el '2023-10-10'\n",
    "        index_separacio = str(x).index(' ') + 1\n",
    "        key = str(x)[index_separacio: index_separacio + 8]\n",
    "        return(workload[key])\n",
    "\n",
    "    gazedata['workload'] = gazedata['timestamp'].apply(assignar_workload)\n",
    "\n",
    "    # Com es pot donar algun cas que se solapin mes de 2 interrupcions, classifiquem aquest moment com a workload 2\n",
    "    gazedata['workload'] = gazedata['workload'].apply(lambda x: 2 if x >= 2 else x)\n",
    "\n",
    "    print(type(interruptions['timestamp']))\n",
    "\n",
    "    \"\"\"Ara calculem el workload_2\"\"\"\n",
    "\n",
    "    workload_2 = trobar_workload_2(interruptions)\n",
    "\n",
    "    def assignar_workload_2(x):\n",
    "\n",
    "        \"\"\"Amb aquesta funció trobem per cada instant que hi ha de gazedata quin workload_2 li correspon, workload_2 és un diccionari que s'ha trobat prèviament\"\"\"\n",
    "\n",
    "        #trobem l'espai que separa la data amb l'hora perque no ens interessa el '2023-10-10'\n",
    "        index_separacio = str(x).index(' ') + 1\n",
    "        key = str(x)[index_separacio: index_separacio + 8]\n",
    "        return(workload_2[key])\n",
    "\n",
    "    # Workload_2 es per cada segon, però per cada segon tenim 60 mesures, així que amb aquesta funció assignem a cada messura el que li toca\n",
    "    gazedata['workload_2'] = gazedata['timestamp'].apply(assignar_workload_2)\n",
    "\n",
    "    # A workload_2 també sumem workload ja que el nombre d'interrupcions simultànies també afecta\n",
    "    gazedata['workload_2'] = gazedata['workload'] + gazedata['workload_2']\n",
    "\n",
    "    # Com volem tenir un workload 0, 1 i 2 dividim workload_2 entre 5 i arrodonim\n",
    "    gazedata['workload_2'] = round(gazedata['workload_2']/2)\n",
    "\n",
    "\n",
    "    gazedata.to_csv('Data/gazedata_csv_definitiu/'+fitxer+'.csv', index=False)\n",
    "\n",
    "    return gazedata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "16:31:18\n",
      "<class 'pandas.core.series.Series'>\n",
      "14:53:52\n",
      "<class 'pandas.core.series.Series'>\n",
      "15:06:36\n",
      "<class 'pandas.core.series.Series'>\n",
      "15:33:32\n",
      "<class 'pandas.core.series.Series'>\n",
      "11:35:58\n",
      "<class 'pandas.core.series.Series'>\n",
      "16:33:05\n",
      "<class 'pandas.core.series.Series'>\n",
      "16:47:16\n",
      "<class 'pandas.core.series.Series'>\n",
      "16:18:36\n",
      "<class 'pandas.core.series.Series'>\n",
      "17:26:47\n",
      "<class 'pandas.core.series.Series'>\n",
      "12:01:22\n",
      "<class 'pandas.core.series.Series'>\n",
      "17:01:20\n",
      "<class 'pandas.core.series.Series'>\n",
      "17:12:43\n",
      "<class 'pandas.core.series.Series'>\n",
      "17:21:23\n"
     ]
    }
   ],
   "source": [
    "for i in df_names:\n",
    "    gazedata_definitiu(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('Data/csv_interruptions/Aura_with_level1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(2.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
